{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc9225d",
   "metadata": {},
   "source": [
    "# Azure ML Workspace Setup\n",
    "\n",
    "This notebook sets up the Azure Machine Learning workspace and configures the environment for LSTM time series forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(find_dotenv(\".env\"))\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab28e4",
   "metadata": {},
   "source": [
    "## 1. Configure Azure ML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b57b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure ML workspace configuration\n",
    "subscription_id = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "resource_group = os.getenv(\"AZURE_RESOURCE_GROUP\")\n",
    "workspace_name = os.getenv(\"AZURE_ML_WORKSPACE\")\n",
    "\n",
    "print(f\"Subscription ID: {subscription_id}\")\n",
    "print(f\"Resource Group: {resource_group}\")\n",
    "print(f\"Workspace Name: {workspace_name}\")\n",
    "\n",
    "# Validate configuration\n",
    "if not all([subscription_id, resource_group, workspace_name]):\n",
    "    print(\"‚ùå Missing required environment variables. Please check your .env file.\")\n",
    "else:\n",
    "    print(\"‚úÖ Configuration loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953de638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure ML client\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    ml_client = MLClient(\n",
    "        credential=credential,\n",
    "        subscription_id=subscription_id,\n",
    "        resource_group_name=resource_group,\n",
    "        workspace_name=workspace_name\n",
    "    )\n",
    "\n",
    "    # Test connection\n",
    "    workspace = ml_client.workspaces.get(workspace_name)\n",
    "    print(f\"‚úÖ Successfully connected to workspace: {workspace.name}\")\n",
    "    print(f\"Location: {workspace.location}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error connecting to workspace: {str(e)}\")\n",
    "    print(\"Please ensure you're authenticated and have access to the workspace.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a0ab1a",
   "metadata": {},
   "source": [
    "## 2. Setup Compute Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to path for module imports\n",
    "parent_dir = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "modules_dir = os.path.join(parent_dir, 'src')\n",
    "if modules_dir not in sys.path:\n",
    "    sys.path.append(modules_dir)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "print(f\"Parent directory: {parent_dir}\")\n",
    "print(f\"Modules directory: {modules_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad7014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and initialize configuration utilities\n",
    "from utils.azure_ml_config import AzureMLConfig\n",
    "\n",
    "# Initialize configuration\n",
    "config = AzureMLConfig()\n",
    "config.validate_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1952c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup compute cluster\n",
    "from mlops.compute.setup_compute import ComputeManager\n",
    "\n",
    "compute_manager = ComputeManager()\n",
    "\n",
    "# Create CPU compute cluster\n",
    "cpu_cluster = compute_manager.create_compute_cluster(\n",
    "    cluster_name=\"cpu-cluster\",\n",
    "    vm_size=\"Standard_D32ds_v5\",\n",
    "    max_instances=4\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ CPU cluster created: {cpu_cluster.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc4306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all compute resources\n",
    "compute_resources = compute_manager.list_compute_resources()\n",
    "print(f\"Total compute resources: {len(compute_resources)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b76522",
   "metadata": {},
   "source": [
    "## 3. Test Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c26bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessing utilities\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_processing.preprocessor import TimeSeriesPreprocessor, load_sample_data\n",
    "\n",
    "# Load sample data\n",
    "data = load_sample_data()\n",
    "print(f\"Loaded data shape: {data.shape}\")\n",
    "print(f\"Data columns: {data.columns.tolist()}\")\n",
    "print(f\"Date range: {data['date'].min()} to {data['date'].max()}\")\n",
    "\n",
    "# Display first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b91d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the time series data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data['date'], data['value'])\n",
    "plt.title('Sample Time Series Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607225f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test preprocessing\n",
    "preprocessor = TimeSeriesPreprocessor(sequence_length=60)\n",
    "\n",
    "# Fit and transform data\n",
    "scaled_data = preprocessor.fit_transform(data)\n",
    "print(f\"Scaled data shape: {scaled_data.shape}\")\n",
    "print(f\"Scaled data range: {scaled_data.min():.3f} to {scaled_data.max():.3f}\")\n",
    "\n",
    "# Create sequences\n",
    "sequences, targets = preprocessor.create_sequences(scaled_data)\n",
    "print(f\"Sequences shape: {sequences.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e741773",
   "metadata": {},
   "source": [
    "## 4. Test Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model\n",
    "import torch\n",
    "\n",
    "from models.lstm_model import LSTMConfig, LSTMTimeSeriesModel\n",
    "\n",
    "# Create model config\n",
    "config = LSTMConfig()\n",
    "print(\"Model configuration:\")\n",
    "for key, value in config.__dict__.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3b5c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = LSTMTimeSeriesModel(\n",
    "    input_size=config.input_size,\n",
    "    hidden_size=config.hidden_size,\n",
    "    num_layers=config.num_layers,\n",
    "    output_size=config.output_size,\n",
    "    dropout=config.dropout\n",
    ")\n",
    "\n",
    "print(\"Model created successfully\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad\n",
    ")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e71d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "sample_input = torch.randn(1, config.sequence_length, config.input_size)\n",
    "output = model(sample_input)\n",
    "print(f\"Input shape: {sample_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(\"‚úÖ Forward pass successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d238c6",
   "metadata": {},
   "source": [
    "## 5. Setup MLflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df0e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# Configure MLflow tracking - using local file system for reliability\n",
    "# This avoids the Azure ML MLflow integration issues while still being functional\n",
    "local_tracking_uri = f\"file://{os.getcwd()}/mlruns\"\n",
    "mlflow.set_tracking_uri(local_tracking_uri)\n",
    "\n",
    "# Set experiment\n",
    "experiment_name = \"lstm-time-series-forecasting-1105\"\n",
    "experiment = mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"‚úÖ MLflow experiment set: {experiment_name}\")\n",
    "print(f\"Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Experiment ID: {experiment.experiment_id}\")\n",
    "\n",
    "# Note: If you need Azure ML MLflow integration later, you can configure it\n",
    "# by ensuring proper authentication and using the workspace's MLflow tracking URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc179d4",
   "metadata": {},
   "source": [
    "## 6. Azure ML Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635da5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available environments\n",
    "environments = list(ml_client.environments.list())\n",
    "print(f\"Found {len(environments)} environments in workspace\")\n",
    "\n",
    "# Look for PyTorch environments\n",
    "pytorch_envs = [env for env in environments if 'pytorch' in env.name.lower()]\n",
    "if pytorch_envs:\n",
    "    print(\"\\nAvailable PyTorch environments:\")\n",
    "    for env in pytorch_envs[:5]:  # Show first 5\n",
    "        print(f\"  - {env.name}:{env.version}\")\n",
    "\n",
    "    # Use the first available PyTorch environment\n",
    "    recommended_env = f\"{pytorch_envs[0].name}@latest\"\n",
    "    print(f\"\\n‚úÖ Recommended environment: {recommended_env}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No PyTorch environments found. Using curated environment.\")\n",
    "    recommended_env = \"AzureML-pytorch-1.13-ubuntu20.04-py38-cpu@latest\" # AzureML-pytorch-1.13-ubuntu20.04-py38-cpu@latest, AzureML-pytorch-1.9-ubuntu18.04-py37-cpu@latest\n",
    "\n",
    "environment_name = recommended_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe20bdce",
   "metadata": {},
   "source": [
    "## 7. Prepare Training Script for Azure ML Remote Execution\n",
    "\n",
    "This section will prepare and submit a training job to run remotely on Azure ML compute cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a2c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Available Environments\n",
    "print(\"üîç Checking available Azure ML curated environments...\")\n",
    "\n",
    "try:\n",
    "    # List available environments\n",
    "    environments = ml_client.environments.list()\n",
    "\n",
    "    # Find PyTorch environments\n",
    "    pytorch_envs = []\n",
    "    for env in environments:\n",
    "        if env.name and \"pytorch\" in env.name.lower():\n",
    "            pytorch_envs.append(f\"{env.name}@{env.version}\" if env.version else env.name)\n",
    "\n",
    "    print(f\"\\\\nüìã Found {len(pytorch_envs)} PyTorch environments:\")\n",
    "    for env in sorted(pytorch_envs)[:10]:  # Show first 10\n",
    "        print(f\"   - {env}\")\n",
    "\n",
    "    # Recommend a working environment\n",
    "    if pytorch_envs:\n",
    "        # Look for a recent stable PyTorch environment\n",
    "        recommended_env = None\n",
    "        for env in pytorch_envs:\n",
    "            if \"cpu\" in env.lower() and (\"2.0\" in env or \"1.13\" in env or \"latest\" in env):\n",
    "                recommended_env = env\n",
    "                break\n",
    "\n",
    "        if not recommended_env:\n",
    "            recommended_env = pytorch_envs[0]  # Use first available\n",
    "\n",
    "        print(f\"\\\\n‚úÖ Recommended environment: {recommended_env}\")\n",
    "        environment_name = f\"{recommended_env}@latest\"\n",
    "\n",
    "    else:\n",
    "        # Fallback to a generic ML environment\n",
    "        print(\"\\\\n‚ö†Ô∏è No PyTorch environments found, using generic ML environment\")\n",
    "        environment_name = \"AzureML-pytorch-1.13-ubuntu20.04-py38-cpu@latest\"\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error checking environments: {str(e)}\")\n",
    "    print(\"\\\\nüîÑ Using alternative approach - creating custom environment\")\n",
    "\n",
    "    # Create a simple custom environment as fallback\n",
    "    from azure.ai.ml.entities import Environment\n",
    "\n",
    "    custom_env = Environment(\n",
    "        name=\"pytorch-lstm-cpu\",\n",
    "        description=\"Custom PyTorch environment for LSTM training\",\n",
    "        conda_file=\"../src/azure_ml_training/environment.yml\",\n",
    "        image=\"mcr.microsoft.com/azureml/base:openmpi4.1.0-ubuntu20.04\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        ml_client.environments.create_or_update(custom_env)\n",
    "        environment_name = \"pytorch-lstm-cpu@latest\"\n",
    "        print(f\"‚úÖ Created custom environment: {environment_name}\")\n",
    "    except Exception as create_error:\n",
    "        print(f\"‚ùå Failed to create custom environment: {str(create_error)}\")\n",
    "        print(\"\\\\nüí° Using minimal base environment\")\n",
    "        environment_name = \"AzureML-minimal-ubuntu20.04-py38-cpu@latest\"\n",
    "\n",
    "print(f\"\\\\nüéØ Final environment selection: {environment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a42c853",
   "metadata": {},
   "source": [
    "## 8. Test Training Job Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e00bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and submit training job\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "print(\"üîÑ Preparing training job submission...\")\n",
    "training_script_dir = \"../src/azure_ml_training\"\n",
    "# Verify training script exists\n",
    "script_path = os.path.join(training_script_dir, \"train_lstm.py\")\n",
    "if not os.path.exists(script_path):\n",
    "    raise FileNotFoundError(f\"Training script not found: {script_path}\")\n",
    "\n",
    "print(f\"‚úÖ Training script verified: {script_path}\")\n",
    "print(f\"Script size: {os.path.getsize(script_path)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c5564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training job\n",
    "training_job = command(\n",
    "    code=training_script_dir,\n",
    "    command=\"python train_lstm.py --epochs 30 --batch_size 32 --learning_rate 0.001\",\n",
    "    environment=environment_name,\n",
    "    compute=\"cpu-cluster\",\n",
    "    experiment_name=\"lstm-time-series-forecasting-test\",\n",
    "    display_name=\"LSTM Training Job\",\n",
    "    description=\"LSTM model training for time series forecasting\",\n",
    "    tags={\n",
    "                \"model_type\": \"LSTM\",\n",
    "                \"framework\": \"PyTorch\",\n",
    "                \"task\": \"time_series_forecasting\",\n",
    "                \"script\": \"train_lstm\"\n",
    "            }\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training job configured\")\n",
    "print(f\"Environment: {environment_name}\")\n",
    "print(\"Compute: cpu-cluster\")\n",
    "print(\"Experiment: lstm-time-series-forecasting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c002b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the training job\n",
    "print(\"üöÄ Submitting the training job...\")\n",
    "\n",
    "try:\n",
    "    # Verify cluster is ready\n",
    "    cluster_check = ml_client.compute.get(\"cpu-cluster\")\n",
    "    if cluster_check.provisioning_state != \"Succeeded\":\n",
    "        raise Exception(f\"Cluster not ready. State: {cluster_check.provisioning_state}\")\n",
    "\n",
    "    print(f\"‚úÖ Cluster ready: {cluster_check.name} (State: {cluster_check.provisioning_state})\")\n",
    "\n",
    "    # Submit the job\n",
    "    submitted_job = ml_client.jobs.create_or_update(training_job)\n",
    "\n",
    "    print(\"\\n‚úÖ Job submitted successfully!\")\n",
    "    print(\"üìã Job Details:\")\n",
    "    print(f\"   Name: {submitted_job.name}\")\n",
    "    print(f\"   Status: {submitted_job.status}\")\n",
    "    print(f\"   Experiment: {submitted_job.experiment_name}\")\n",
    "    print(f\"   Compute: {submitted_job.compute}\")\n",
    "    print(f\"   Environment: {environment_name}\")\n",
    "\n",
    "    print(\"\\nüîó Monitoring Links:\")\n",
    "    print(f\"   Studio URL: {submitted_job.studio_url}\")\n",
    "\n",
    "    # Store for monitoring\n",
    "    submitted_job_name = submitted_job.name\n",
    "    print(f\"\\nüí° Job '{submitted_job_name}' is now running!\")\n",
    "    print(\"   Use the Studio URL above to monitor progress\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Job submission failed: {str(e)}\")\n",
    "    print(\"\\nüîß Troubleshooting tips:\")\n",
    "    print(\"1. Ensure the compute cluster is in 'Succeeded' state\")\n",
    "    print(\"2. Check that the environment is available\")\n",
    "    print(\"3. Verify the training script exists and is valid\")\n",
    "    print(\"4. Check Azure ML workspace permissions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867c46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä MONITOR FIXED JOB (Check if tracking_uri error is resolved)\n",
    "print(\"üìä Monitoring Fixed Job Status\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Check if we have a fixed job to monitor\n",
    "    if 'submitted_job_name' in globals() and submitted_job_name:\n",
    "        print(f\"üîç Monitoring job: {submitted_job_name}\")\n",
    "\n",
    "        # Get current job status\n",
    "        current_submitted_job = ml_client.jobs.get(submitted_job_name)\n",
    "\n",
    "        print(\"\\nüìã Job Status:\")\n",
    "        print(f\"   Name: {current_submitted_job.name}\")\n",
    "        print(f\"   Status: {current_submitted_job.status}\")\n",
    "        print(f\"   Created: {current_submitted_job.creation_context.created_at}\")\n",
    "\n",
    "        if hasattr(current_submitted_job, 'start_time') and current_submitted_job.start_time:\n",
    "            print(f\"   Started: {current_submitted_job.start_time}\")\n",
    "\n",
    "        if hasattr(current_submitted_job, 'end_time') and current_submitted_job.end_time:\n",
    "            print(f\"   Ended: {current_submitted_job.end_time}\")\n",
    "\n",
    "        # Show studio URL for monitoring\n",
    "        if hasattr(current_submitted_job, 'studio_url') and current_submitted_job.studio_url:\n",
    "            print(\"\\nüîó Monitor in Azure ML Studio:\")\n",
    "            print(f\"   {current_submitted_job.studio_url}\")\n",
    "\n",
    "        # Provide status-specific guidance\n",
    "        status = current_submitted_job.status\n",
    "\n",
    "        if status == \"Completed\":\n",
    "            print(\"\\nüéâ Job completed successfully!\")\n",
    "            print(\"   ‚úÖ MLflow tracking_uri error has been resolved!\")\n",
    "            print(\"   ‚úÖ Model training completed without MLflow issues\")\n",
    "            print(\"   üìÅ Check outputs in Azure ML Studio\")\n",
    "            print(\"   üìä Training metrics should be logged properly\")\n",
    "\n",
    "        elif status == \"Failed\":\n",
    "            print(\"\\n‚ùå Job failed!\")\n",
    "            print(\"   üîç Check Azure ML Studio for detailed error logs\")\n",
    "            print(\"   üìã Common issues to check:\")\n",
    "            print(\"      - Compute cluster problems\")\n",
    "            print(\"      - Environment setup issues\")\n",
    "            print(\"      - Storage permission errors\")\n",
    "            print(\"      - Network connectivity\")\n",
    "\n",
    "        elif status in [\"Running\", \"Preparing\"]:\n",
    "            print(f\"\\n‚è≥ Job is {status.lower()}...\")\n",
    "            if status == \"Preparing\":\n",
    "                print(\"   üîß Setting up compute environment\")\n",
    "                print(\"   üì¶ Installing dependencies\")\n",
    "                print(\"   ‚è±Ô∏è This typically takes 3-5 minutes\")\n",
    "            else:\n",
    "                print(\"   üèÉ‚Äç‚ôÇÔ∏è Training script is executing\")\n",
    "                print(\"   üìä MLflow compatibility layer is active\")\n",
    "                print(\"   ‚úÖ Should handle tracking_uri errors gracefully\")\n",
    "\n",
    "        elif status == \"Queued\":\n",
    "            print(\"\\n‚è∞ Job is queued...\")\n",
    "            print(\"   ‚è≥ Waiting for compute resources\")\n",
    "            print(\"   üîß Compute cluster is starting up\")\n",
    "\n",
    "        elif status == \"Canceled\":\n",
    "            print(\"\\nüõë Job was canceled\")\n",
    "            print(\"   üîÑ You can restart with the same configuration\")\n",
    "\n",
    "        # Additional diagnostic info\n",
    "        print(\"\\nüîç Troubleshooting Info:\")\n",
    "        print(\"   Job Type: Command Job\")\n",
    "        print(\"   Environment: Curated PyTorch (should avoid MLflow conflicts)\")\n",
    "        print(\"   Script: Fixed version with error handling\")\n",
    "        print(\"   Expected Duration: 5-15 minutes\")\n",
    "\n",
    "        # Check recent jobs if this one isn't running\n",
    "        if status in [\"Failed\", \"Canceled\", \"Completed\"]:\n",
    "            print(\"\\nüìã Recent Job History:\")\n",
    "            recent_jobs = list(ml_client.jobs.list(max_results=3))\n",
    "            for job in recent_jobs:\n",
    "                print(f\"   - {job.name}: {job.status} ({job.creation_context.created_at})\")\n",
    "\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è No fixed job to monitor yet.\")\n",
    "        print(\"   Run the previous cell to submit the fixed job first\")\n",
    "\n",
    "        # Show regular job monitoring\n",
    "        print(\"\\nüìã All Recent Jobs:\")\n",
    "        recent_jobs = list(ml_client.jobs.list(max_results=5))\n",
    "\n",
    "        if recent_jobs:\n",
    "            for job in recent_jobs:\n",
    "                status_emoji = \"‚úÖ\" if job.status == \"Completed\" else \"‚ùå\" if job.status == \"Failed\" else \"‚è≥\"\n",
    "                print(f\"   {status_emoji} {job.name}: {job.status}\")\n",
    "\n",
    "                # Check if any recent job had the tracking_uri error\n",
    "                if job.status == \"Failed\":\n",
    "                    print(\"      üîç Check this job for tracking_uri errors in Azure ML Studio\")\n",
    "        else:\n",
    "            print(\"   No recent jobs found\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error monitoring job: {str(e)}\")\n",
    "    print(\"\\nüîß Try:\")\n",
    "    print(\"   - Refresh your connection to Azure ML\")\n",
    "    print(\"   - Check job status directly in Azure ML Studio\")\n",
    "    print(\"   - Verify the job name is correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426052a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for job management\n",
    "def list_recent_jobs(ml_client, limit=5):\n",
    "    \"\"\"List recent training jobs\"\"\"\n",
    "    print(f\"üìã Recent training jobs (last {limit}):\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    try:\n",
    "        jobs = ml_client.jobs.list(max_results=limit)\n",
    "        for job in jobs:\n",
    "            print(f\"Name: {job.name}\")\n",
    "            print(f\"Status: {job.status}\")\n",
    "            print(f\"Created: {job.creation_context.created_at}\")\n",
    "            print(f\"Experiment: {job.experiment_name}\")\n",
    "            print(f\"Studio: {job.studio_url}\")\n",
    "            print(\"-\" * 40)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error listing jobs: {str(e)}\")\n",
    "\n",
    "def get_job_logs(ml_client, job_name):\n",
    "    \"\"\"Get job logs and outputs\"\"\"\n",
    "    try:\n",
    "        job = ml_client.jobs.get(job_name)\n",
    "        print(f\"üìÑ Job: {job_name}\")\n",
    "        print(f\"Status: {job.status}\")\n",
    "        print(f\"Studio URL: {job.studio_url}\")\n",
    "\n",
    "        if job.status == \"Completed\":\n",
    "            print(\"‚úÖ Job completed successfully!\")\n",
    "            # You can download outputs here if needed\n",
    "        elif job.status == \"Failed\":\n",
    "            print(\"‚ùå Job failed. Check the Studio URL for detailed logs.\")\n",
    "\n",
    "        return job\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error getting job info: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def cancel_job(ml_client, job_name):\n",
    "    \"\"\"Cancel a running job\"\"\"\n",
    "    try:\n",
    "        ml_client.jobs.cancel(job_name)\n",
    "        print(f\"üõë Job {job_name} cancellation requested\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error canceling job: {str(e)}\")\n",
    "\n",
    "# Show available functions\n",
    "print(\"üõ†Ô∏è Available job management functions:\")\n",
    "print(\"  - list_recent_jobs(ml_client, limit=5)\")\n",
    "print(\"  - get_job_logs(ml_client, job_name)\")\n",
    "print(\"  - cancel_job(ml_client, job_name)\")\n",
    "print(\"  - monitor_job(job_name, ml_client, check_interval=30)\")\n",
    "print()\n",
    "print(\"Example usage:\")\n",
    "print(\"  list_recent_jobs(ml_client)\")\n",
    "if 'job_name' in locals() and job_name:\n",
    "    print(f\"  get_job_logs(ml_client, '{job_name}')\")\n",
    "    print(f\"  cancel_job(ml_client, '{job_name}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000555df",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_recent_jobs(ml_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1225feb",
   "metadata": {},
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02a5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéâ Azure ML Workspace Setup Complete!\")\n",
    "print(\"\\n‚úÖ What's been set up:\")\n",
    "print(\"1. Azure ML workspace connection and authentication\")\n",
    "print(\"2. Compute cluster for training\")\n",
    "print(\"3. MLflow experiment tracking\")\n",
    "print(\"4. Sample data preprocessing pipeline\")\n",
    "print(\"5. LSTM model architecture\")\n",
    "print(\"6. Azure ML training script and environment\")\n",
    "print(\"7. Remote training job submission capabilities\")\n",
    "\n",
    "print(\"\\nüìÅ Created files:\")\n",
    "print(\"- ../src/azure_ml_training/train_lstm.py (Training script)\")\n",
    "print(\"- ../src/azure_ml_training/environment.yml (Conda environment)\")\n",
    "print(\"- ../src/azure_ml_training/requirements.txt (Pip requirements)\")\n",
    "\n",
    "print(\"\\nüöÄ Next steps:\")\n",
    "print(\"1. Review the generated training script in src/azure_ml_training/\")\n",
    "print(\"2. Customize the model hyperparameters as needed\")\n",
    "print(\"3. Run the cells above to submit training jobs to Azure ML\")\n",
    "print(\"4. Monitor training progress in Azure ML Studio\")\n",
    "print(\"5. Deploy the trained model using Azure ML endpoints\")\n",
    "\n",
    "print(\"\\nüí° Available options:\")\n",
    "print(\"- Local training: python src/training/train_lstm.py\")\n",
    "print(\"- Azure ML training: Submit job using the cells above\")\n",
    "print(\"- Hybrid approach: Develop locally, train remotely\")\n",
    "\n",
    "if 'job_name' in locals() and job_name:\n",
    "    print(f\"\\nüîó Current job: {job_name}\")\n",
    "    print(f\"Monitor at: {submitted_job.studio_url}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No active training job. Run the submission cells above to start training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_env",
   "language": "python",
   "name": "aml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
