{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa218529",
   "metadata": {},
   "source": [
    "# Azure ML Training Tutorial: LSTM Time Series Forecasting\n",
    "\n",
    "This notebook provides a step-by-step guide to prepare, submit, and monitor LSTM training jobs on Azure ML. You'll learn how to:\n",
    "\n",
    "1. **Setup Azure ML Environment** - Connect to workspace and configure resources\n",
    "2. **Create Training Scripts** - Develop Azure ML optimized training code\n",
    "3. **Submit Remote Jobs** - Execute training on Azure ML compute clusters\n",
    "4. **Monitor Progress** - Track job status and retrieve results\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Azure ML workspace (created in `01_setup_workspace.ipynb`)\n",
    "- Environment variables configured for Azure authentication\n",
    "- Azure CLI authenticated or service principal setup\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "- ‚úÖ Understand Azure ML training job workflow\n",
    "- ‚úÖ Create self-contained training scripts for remote execution\n",
    "- ‚úÖ Configure environments and compute resources\n",
    "- ‚úÖ Submit and monitor training jobs\n",
    "- ‚úÖ Retrieve training outputs and artifacts\n",
    "\n",
    "Let's get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e598e4e",
   "metadata": {},
   "source": [
    "## Step 1: Install and Import Required Libraries\n",
    "\n",
    "First, we'll install and import all necessary libraries for Azure ML operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b26c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Azure ML imports\n",
    "from azure.ai.ml import MLClient, command\n",
    "from azure.ai.ml.entities import Environment\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Utility imports\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "print(\"üìö Importing libraries...\")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(find_dotenv(\".env\"))\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(\"üîß Environment variables loaded from .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf94f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to path for module imports\n",
    "parent_dir = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "modules_dir = os.path.join(parent_dir, 'src')\n",
    "if modules_dir not in sys.path:\n",
    "    sys.path.append(modules_dir)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "print(f\"Parent directory: {parent_dir}\")\n",
    "print(f\"Modules directory: {modules_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cb76ca",
   "metadata": {},
   "source": [
    "## Step 2: Configure Azure ML Workspace Connection\n",
    "\n",
    "Next, we'll establish a connection to your Azure ML workspace using managed identity authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72369be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Azure ML workspace configuration from environment variables\n",
    "subscription_id = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "resource_group = os.getenv(\"AZURE_RESOURCE_GROUP\")\n",
    "workspace_name = os.getenv(\"AZURE_ML_WORKSPACE\")\n",
    "\n",
    "print(\"üîß Azure ML Configuration:\")\n",
    "print(f\"   Subscription ID: {subscription_id}\")\n",
    "print(f\"   Resource Group: {resource_group}\")\n",
    "print(f\"   Workspace Name: {workspace_name}\")\n",
    "\n",
    "# Validate required configuration\n",
    "if not all([subscription_id, resource_group, workspace_name]):\n",
    "    print(\"\\n‚ùå Missing required environment variables!\")\n",
    "    print(\"Please set the following in your .env file:\")\n",
    "    print(\"   - AZURE_SUBSCRIPTION_ID\")\n",
    "    print(\"   - AZURE_RESOURCE_GROUP\")\n",
    "    print(\"   - AZURE_ML_WORKSPACE\")\n",
    "    raise ValueError(\"Missing Azure ML configuration\")\n",
    "\n",
    "print(\"\\n‚úÖ Configuration validation passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure ML client with managed identity authentication\n",
    "print(\"üîê Authenticating with Azure...\")\n",
    "\n",
    "try:\n",
    "    # Use DefaultAzureCredential for secure authentication\n",
    "    # This supports multiple auth methods: managed identity, Azure CLI, etc.\n",
    "    credential = DefaultAzureCredential()\n",
    "\n",
    "    # Create Azure ML client\n",
    "    ml_client = MLClient(\n",
    "        credential=credential,\n",
    "        subscription_id=subscription_id,\n",
    "        resource_group_name=resource_group,\n",
    "        workspace_name=workspace_name\n",
    "    )\n",
    "\n",
    "    # Test connection by retrieving workspace details\n",
    "    workspace = ml_client.workspaces.get(workspace_name)\n",
    "\n",
    "    print(\"‚úÖ Successfully connected to Azure ML workspace!\")\n",
    "    print(f\"   Workspace: {workspace.name}\")\n",
    "    print(f\"   Location: {workspace.location}\")\n",
    "    print(f\"   Resource Group: {workspace.resource_group}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error connecting to Azure ML workspace: {str(e)}\")\n",
    "    print(\"\\nüîß Troubleshooting tips:\")\n",
    "    print(\"   1. Ensure you're authenticated with Azure CLI: 'az login'\")\n",
    "    print(\"   2. Verify workspace exists and you have access\")\n",
    "    print(\"   3. Check environment variables are correct\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87313f",
   "metadata": {},
   "source": [
    "## Step 3: Setup and Validate Compute Resources\n",
    "\n",
    "We need compute resources to run our training jobs. Let's check existing compute or create new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List existing compute resources\n",
    "print(\"üñ•Ô∏è Checking existing compute resources...\")\n",
    "\n",
    "try:\n",
    "    compute_list = list(ml_client.compute.list())\n",
    "\n",
    "    if compute_list:\n",
    "        print(f\"‚úÖ Found {len(compute_list)} compute resource(s):\")\n",
    "        for compute in compute_list:\n",
    "            print(f\"   - {compute.name} ({compute.type}) - {compute.provisioning_state}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No compute resources found in workspace\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error listing compute resources: {str(e)}\")\n",
    "    compute_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4453bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create compute cluster if needed\n",
    "# from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "# compute_name = \"training-cluster\"\n",
    "# found_compute = None\n",
    "\n",
    "# # Check if our target compute exists\n",
    "# for compute in compute_list:\n",
    "#     if compute.name == compute_name:\n",
    "#         found_compute = compute\n",
    "#         break\n",
    "\n",
    "# if found_compute:\n",
    "#     print(f\"‚úÖ Using existing compute cluster: {compute_name}\")\n",
    "#     print(f\"   State: {found_compute.provisioning_state}\")\n",
    "#     print(f\"   VM Size: {found_compute.size}\")\n",
    "# else:\n",
    "#     print(f\"üî® Creating new compute cluster: {compute_name}\")\n",
    "\n",
    "#     # Define compute cluster configuration\n",
    "#     compute_cluster = AmlCompute(\n",
    "#         name=compute_name,\n",
    "#         description=\"CPU cluster for LSTM training\",\n",
    "#         size=\"Standard_D2s_v3\",  # 2 cores, 8GB RAM - good for small models\n",
    "#         min_instances=0,         # Scale to zero when not in use\n",
    "#         max_instances=4,         # Maximum nodes\n",
    "#         idle_time_before_scale_down=1800  # 30 minutes\n",
    "#     )\n",
    "\n",
    "#     try:\n",
    "#         # Create the compute cluster\n",
    "#         created_compute = ml_client.compute.begin_create_or_update(compute_cluster)\n",
    "#         print(\"‚è≥ Creating compute cluster (this may take a few minutes)...\")\n",
    "\n",
    "#         # Note: We don't wait for completion as it can take several minutes\n",
    "#         print(\"‚úÖ Compute cluster creation initiated!\")\n",
    "#         print(f\"   Monitor progress in Azure ML Studio\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error creating compute cluster: {str(e)}\")\n",
    "#         print(\"üí° You can use any existing compute cluster for training\")\n",
    "\n",
    "#         # Fallback to first available compute\n",
    "#         if compute_list:\n",
    "#             compute_name = compute_list[0].name\n",
    "#             print(f\"üîÑ Using fallback compute: {compute_name}\")\n",
    "#         else:\n",
    "#             raise RuntimeError(\"No compute resources available\")\n",
    "\n",
    "# Setup compute cluster\n",
    "from mlops.compute.setup_compute import ComputeManager\n",
    "\n",
    "compute_manager = ComputeManager()\n",
    "\n",
    "# Create CPU compute cluster\n",
    "cpu_cluster = compute_manager.create_compute_cluster(\n",
    "    cluster_name=\"cpu-cluster\",\n",
    "    vm_size=\"Standard_D32ds_v5\",\n",
    "    max_instances=4\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ Target compute for training: {cpu_cluster}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36cd98f",
   "metadata": {},
   "source": [
    "## Step 4: Create and Register Azure ML Environment\n",
    "\n",
    "We need to define the software environment (Python packages) for our training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67d6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training environment directory\n",
    "training_dir = Path(\"../src/azure_ml_training\")\n",
    "training_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Created training directory: {training_dir}\")\n",
    "\n",
    "# Create conda environment specification\n",
    "environment_content = \"\"\"\n",
    "name: pytorch-lstm-env\n",
    "channels:\n",
    "  - pytorch\n",
    "  - conda-forge\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.9\n",
    "  - pytorch>=1.12.0\n",
    "  - numpy\n",
    "  - pandas\n",
    "  - scikit-learn\n",
    "  - pip\n",
    "  - pip:\n",
    "    - mlflow>=2.0.0\n",
    "    - azure-ai-ml\n",
    "    - joblib\n",
    "\"\"\"\n",
    "\n",
    "# Write environment file\n",
    "env_file_path = training_dir / \"environment.yml\"\n",
    "with open(env_file_path, 'w') as f:\n",
    "    f.write(environment_content.strip())\n",
    "\n",
    "print(f\"‚úÖ Created environment file: {env_file_path}\")\n",
    "\n",
    "# Also create requirements.txt for reference\n",
    "requirements_content = \"\"\"\n",
    "torch>=1.12.0\n",
    "numpy\n",
    "pandas\n",
    "scikit-learn\n",
    "mlflow>=2.0.0\n",
    "azure-ai-ml\n",
    "joblib\n",
    "\"\"\"\n",
    "\n",
    "requirements_path = training_dir / \"requirements.txt\"\n",
    "with open(requirements_path, 'w') as f:\n",
    "    f.write(requirements_content.strip())\n",
    "\n",
    "print(f\"‚úÖ Created requirements file: {requirements_path}\")\n",
    "print(\"üì¶ Environment includes: PyTorch, MLflow, scikit-learn, and Azure ML SDK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3a8a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the environment with Azure ML\n",
    "environment_name = \"pytorch-lstm-env\"\n",
    "\n",
    "print(f\"üîÑ Registering environment: {environment_name}\")\n",
    "\n",
    "try:\n",
    "    # Create environment definition\n",
    "    pytorch_env = Environment(\n",
    "        name=environment_name,\n",
    "        description=\"PyTorch environment for LSTM time series forecasting\",\n",
    "        conda_file=str(env_file_path),\n",
    "        image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\"\n",
    "    )\n",
    "\n",
    "    # Register with Azure ML\n",
    "    registered_env = ml_client.environments.create_or_update(pytorch_env)\n",
    "\n",
    "    print(\"‚úÖ Environment registered successfully!\")\n",
    "    print(f\"   Name: {registered_env.name}\")\n",
    "    print(f\"   Version: {registered_env.version}\")\n",
    "    print(\"   Status: Ready for use\")\n",
    "\n",
    "    # Store for later use\n",
    "    env_reference = f\"{registered_env.name}:{registered_env.version}\"\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error registering environment: {str(e)}\")\n",
    "    print(\"üîÑ Falling back to curated environment...\")\n",
    "\n",
    "    # Use a curated PyTorch environment as fallback\n",
    "    env_reference = \"AzureML-pytorch-1.13-ubuntu20.04-py38-cpu-inference:latest\"\n",
    "    print(f\"‚úÖ Using curated environment: {env_reference}\")\n",
    "\n",
    "print(f\"\\nüéØ Environment for training: {env_reference}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8486befb",
   "metadata": {},
   "source": [
    "## Step 5: Create Training Script for Azure ML\n",
    "\n",
    "Now we'll create a training script specifically optimized for Azure ML. This script will include data generation, model training, and MLflow integration for experiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1662cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Azure ML optimized training script\n",
    "training_script_content = '''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import argparse\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import json\n",
    "\n",
    "\n",
    "class LSTMTimeSeriesModel(nn.Module):\n",
    "    \"\"\"LSTM model for time series forecasting\"\"\"\n",
    "\n",
    "    def __init__(self, input_size=1, hidden_size=50, num_layers=2, output_size=1, dropout=0.2):\n",
    "        super(LSTMTimeSeriesModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
    "                           batch_first=True, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Apply dropout and linear layer to the last output\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def generate_synthetic_data(n_samples=1000, sequence_length=50):\n",
    "    \"\"\"Generate synthetic time series data\"\"\"\n",
    "    print(f\"üîÑ Generating {n_samples} samples with sequence length {sequence_length}\")\n",
    "\n",
    "    # Generate time series with trend and seasonality\n",
    "    t = np.linspace(0, 4*np.pi, n_samples + sequence_length)\n",
    "\n",
    "    # Create complex time series\n",
    "    trend = 0.01 * t\n",
    "    seasonal = 2 * np.sin(t) + 0.5 * np.sin(3*t)\n",
    "    noise = 0.1 * np.random.randn(len(t))\n",
    "\n",
    "    data = trend + seasonal + noise\n",
    "\n",
    "    # Create sequences\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:(i + sequence_length)])\n",
    "        y.append(data[i + sequence_length])\n",
    "\n",
    "    X = np.array(X).reshape(-1, sequence_length, 1)\n",
    "    y = np.array(y).reshape(-1, 1)\n",
    "\n",
    "    # Train/test split\n",
    "    split_idx = int(0.8 * len(X))\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "    print(f\"‚úÖ Data generated - Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train, X_test, y_test, config):\n",
    "    \"\"\"Train the LSTM model with MLflow tracking\"\"\"\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.FloatTensor(y_train)\n",
    "    X_test_tensor = torch.FloatTensor(X_test)\n",
    "    y_test_tensor = torch.FloatTensor(y_test)\n",
    "\n",
    "    # Initialize model\n",
    "    model = LSTMTimeSeriesModel(\n",
    "        input_size=config['input_size'],\n",
    "        hidden_size=config['hidden_size'],\n",
    "        num_layers=config['num_layers'],\n",
    "        output_size=config['output_size'],\n",
    "        dropout=config['dropout']\n",
    "    )\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    print(f\"üöÄ Starting training for {config['epochs']} epochs\")\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(config['epochs']):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Log metrics every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_outputs = model(X_test_tensor)\n",
    "                test_loss = criterion(test_outputs, y_test_tensor)\n",
    "\n",
    "                # Log to MLflow\n",
    "                mlflow.log_metric(\"train_loss\", loss.item(), step=epoch)\n",
    "                mlflow.log_metric(\"test_loss\", test_loss.item(), step=epoch)\n",
    "\n",
    "                print(f\"Epoch [{epoch+1}/{config['epochs']}] - \"\n",
    "                      f\"Train Loss: {loss.item():.6f}, Test Loss: {test_loss.item():.6f}\")\n",
    "\n",
    "            model.train()\n",
    "\n",
    "    # Final evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_pred = model(X_train_tensor).numpy()\n",
    "        test_pred = model(X_test_tensor).numpy()\n",
    "\n",
    "        # Calculate final metrics\n",
    "        train_mse = mean_squared_error(y_train, train_pred)\n",
    "        test_mse = mean_squared_error(y_test, test_pred)\n",
    "        train_mae = mean_absolute_error(y_train, train_pred)\n",
    "        test_mae = mean_absolute_error(y_test, test_pred)\n",
    "\n",
    "        # Log final metrics\n",
    "        mlflow.log_metric(\"final_train_mse\", train_mse)\n",
    "        mlflow.log_metric(\"final_test_mse\", test_mse)\n",
    "        mlflow.log_metric(\"final_train_mae\", train_mae)\n",
    "        mlflow.log_metric(\"final_test_mae\", test_mae)\n",
    "\n",
    "        print(f\"\\\\nüìä Final Results:\")\n",
    "        print(f\"   Train MSE: {train_mse:.6f}\")\n",
    "        print(f\"   Test MSE: {test_mse:.6f}\")\n",
    "        print(f\"   Train MAE: {train_mae:.6f}\")\n",
    "        print(f\"   Test MAE: {test_mae:.6f}\")\n",
    "\n",
    "    return model, test_mse\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='LSTM Time Series Training')\n",
    "    parser.add_argument('--epochs', type=int, default=100, help='Number of epochs')\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.001, help='Learning rate')\n",
    "    parser.add_argument('--hidden_size', type=int, default=50, help='LSTM hidden size')\n",
    "    parser.add_argument('--num_layers', type=int, default=2, help='Number of LSTM layers')\n",
    "    parser.add_argument('--dropout', type=float, default=0.2, help='Dropout rate')\n",
    "    parser.add_argument('--sequence_length', type=int, default=50, help='Input sequence length')\n",
    "    parser.add_argument('--n_samples', type=int, default=1000, help='Number of data samples')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'epochs': args.epochs,\n",
    "        'learning_rate': args.learning_rate,\n",
    "        'hidden_size': args.hidden_size,\n",
    "        'num_layers': args.num_layers,\n",
    "        'dropout': args.dropout,\n",
    "        'sequence_length': args.sequence_length,\n",
    "        'n_samples': args.n_samples,\n",
    "        'input_size': 1,\n",
    "        'output_size': 1\n",
    "    }\n",
    "\n",
    "    print(\"üéØ Starting Azure ML LSTM Training\")\n",
    "    print(f\"üìã Configuration: {json.dumps(config, indent=2)}\")\n",
    "\n",
    "    # Set up MLflow\n",
    "    mlflow.start_run()\n",
    "\n",
    "    try:\n",
    "        # Log parameters\n",
    "        mlflow.log_params(config)\n",
    "\n",
    "        # Generate data\n",
    "        X_train, X_test, y_train, y_test = generate_synthetic_data(\n",
    "            n_samples=config['n_samples'],\n",
    "            sequence_length=config['sequence_length']\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        model, test_mse = train_model(X_train, y_train, X_test, y_test, config)\n",
    "\n",
    "        # Save model\n",
    "        model_path = \"lstm_model\"\n",
    "        mlflow.pytorch.log_model(model, model_path)\n",
    "\n",
    "        # Create model info file\n",
    "        model_info = {\n",
    "            \"model_type\": \"LSTM Time Series\",\n",
    "            \"framework\": \"PyTorch\",\n",
    "            \"final_test_mse\": float(test_mse),\n",
    "            \"parameters\": config\n",
    "        }\n",
    "\n",
    "        # Save model info\n",
    "        with open(\"model_info.json\", \"w\") as f:\n",
    "            json.dump(model_info, f, indent=2)\n",
    "\n",
    "        mlflow.log_artifact(\"model_info.json\")\n",
    "\n",
    "        print(f\"\\\\n‚úÖ Training completed successfully!\")\n",
    "        print(f\"üìÅ Model saved to MLflow\")\n",
    "        print(f\"üéØ Final Test MSE: {test_mse:.6f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training failed: {str(e)}\")\n",
    "        mlflow.log_param(\"status\", \"failed\")\n",
    "        mlflow.log_param(\"error\", str(e))\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        mlflow.end_run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Create the training script file\n",
    "training_script_path = Path(\"../src/azure_ml_training/train_lstm_azureml.py\")\n",
    "training_script_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(training_script_path, 'w') as f:\n",
    "    f.write(training_script_content)\n",
    "\n",
    "print(f\"‚úÖ Training script created: {training_script_path}\")\n",
    "print(\"üìã Script features:\")\n",
    "print(\"   ‚Ä¢ LSTM model with configurable architecture\")\n",
    "print(\"   ‚Ä¢ Synthetic time series data generation\")\n",
    "print(\"   ‚Ä¢ MLflow experiment tracking\")\n",
    "print(\"   ‚Ä¢ Command-line argument parsing\")\n",
    "print(\"   ‚Ä¢ Error handling and logging\")\n",
    "print(\"   ‚Ä¢ Model saving and artifact logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d51ee9",
   "metadata": {},
   "source": [
    "## Step 6: Submit Training Job to Azure ML\n",
    "\n",
    "Now we'll create and submit a training job to Azure ML. This will run our training script on the remote compute cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bdc324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required classes for job submission\n",
    "\n",
    "# Training job configuration\n",
    "job_config = {\n",
    "    \"experiment_name\": \"lstm-time-series-tutorial\",\n",
    "    \"display_name\": \"LSTM Time Series Training - Tutorial\",\n",
    "    \"description\": \"Training LSTM model for time series forecasting on Azure ML\",\n",
    "    \"code_path\": \"../src/azure_ml_training\",  # Directory containing our training script\n",
    "    \"command\": \"python train_lstm_azureml.py --epochs 50 --learning_rate 0.001 --hidden_size 64 --num_layers 2\",\n",
    "    \"environment\": env_reference,  # Environment we created earlier\n",
    "    \"compute_target\": compute_name,  # Compute cluster we verified earlier\n",
    "    \"instance_count\": 1,\n",
    "    \"max_duration_in_seconds\": 3600  # 1 hour timeout\n",
    "}\n",
    "\n",
    "print(\"üéØ Job Configuration:\")\n",
    "print(f\"   Experiment: {job_config['experiment_name']}\")\n",
    "print(f\"   Environment: {job_config['environment']}\")\n",
    "print(f\"   Compute: {job_config['compute_target']}\")\n",
    "print(f\"   Command: {job_config['command']}\")\n",
    "print(f\"   Timeout: {job_config['max_duration_in_seconds']} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29b1743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and submit the training job\n",
    "print(\"üöÄ Creating Azure ML training job...\")\n",
    "\n",
    "try:\n",
    "    # Create the command job\n",
    "    training_job = command(\n",
    "        code=job_config[\"code_path\"],\n",
    "        command=job_config[\"command\"],\n",
    "        environment=job_config[\"environment\"],\n",
    "        compute=job_config[\"compute_target\"],\n",
    "        display_name=job_config[\"display_name\"],\n",
    "        description=job_config[\"description\"],\n",
    "        experiment_name=job_config[\"experiment_name\"],\n",
    "        # Resource configuration\n",
    "        instance_count=job_config[\"instance_count\"],\n",
    "        # Timeout configuration\n",
    "        timeout=job_config[\"max_duration_in_seconds\"]\n",
    "    )\n",
    "\n",
    "    print(\"üì§ Submitting job to Azure ML...\")\n",
    "\n",
    "    # Submit the job\n",
    "    submitted_job = ml_client.jobs.create_or_update(training_job)\n",
    "\n",
    "    print(\"‚úÖ Job submitted successfully!\")\n",
    "    print(\"üìã Job Details:\")\n",
    "    print(f\"   Job Name: {submitted_job.name}\")\n",
    "    print(f\"   Job ID: {submitted_job.id}\")\n",
    "    print(f\"   Status: {submitted_job.status}\")\n",
    "    print(f\"   Experiment: {submitted_job.experiment_name}\")\n",
    "\n",
    "    # Store job info for monitoring\n",
    "    job_name = submitted_job.name\n",
    "    job_id = submitted_job.id\n",
    "\n",
    "    print(\"\\\\nüîó Job URLs:\")\n",
    "    print(f\"   Studio URL: https://ml.azure.com/runs/{job_name}\")\n",
    "    print(f\"   Direct Link: {submitted_job.studio_url}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error submitting job: {str(e)}\")\n",
    "    print(\"üîç Check that:\")\n",
    "    print(f\"   ‚Ä¢ Compute cluster '{compute_name}' is available\")\n",
    "    print(f\"   ‚Ä¢ Environment '{env_reference}' is valid\")\n",
    "    print(f\"   ‚Ä¢ Training script exists at '{job_config['code_path']}'\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227e4cc0",
   "metadata": {},
   "source": [
    "## Step 7: Monitor Training Job\n",
    "\n",
    "Let's monitor the training job progress and check its status. We can view logs and track the training metrics in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f108d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check job status\n",
    "print(f\"üîç Checking status of job: {job_name}\")\n",
    "\n",
    "try:\n",
    "    # Get current job status\n",
    "    current_job = ml_client.jobs.get(job_name)\n",
    "\n",
    "    print(f\"üìä Job Status: {current_job.status}\")\n",
    "    print(f\"üïê Created: {current_job.creation_context.created_at}\")\n",
    "    print(f\"üéØ Experiment: {current_job.experiment_name}\")\n",
    "\n",
    "    # Display different information based on job status\n",
    "    if current_job.status == \"Completed\":\n",
    "        print(\"‚úÖ Job completed successfully!\")\n",
    "        print(f\"‚è±Ô∏è Duration: {current_job.creation_context.last_modified_at - current_job.creation_context.created_at}\")\n",
    "\n",
    "    elif current_job.status == \"Running\":\n",
    "        print(\"üèÉ‚Äç‚ôÇÔ∏è Job is currently running...\")\n",
    "        print(f\"‚è±Ô∏è Running for: {current_job.creation_context.last_modified_at - current_job.creation_context.created_at}\")\n",
    "\n",
    "    elif current_job.status == \"Failed\":\n",
    "        print(\"‚ùå Job failed!\")\n",
    "        print(\"üîç Check the logs for error details\")\n",
    "\n",
    "    elif current_job.status in [\"Queued\", \"Starting\", \"Preparing\"]:\n",
    "        print(f\"‚è≥ Job is {current_job.status.lower()}...\")\n",
    "        print(\"üí° This may take a few minutes as Azure ML provisions resources\")\n",
    "\n",
    "    else:\n",
    "        print(f\"üìã Current status: {current_job.status}\")\n",
    "\n",
    "    # Show studio URL for detailed monitoring\n",
    "    print(\"\\\\nüåê Monitor in Azure ML Studio:\")\n",
    "    print(f\"   {current_job.studio_url}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error checking job status: {str(e)}\")\n",
    "    print(\"üí° Job might not exist or you may not have access\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c3694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for job completion (optional)\n",
    "\n",
    "def wait_for_job_completion(job_name, max_wait_minutes=30, check_interval=30):\n",
    "    \"\"\"\n",
    "    Wait for job completion with periodic status updates\n",
    "\n",
    "    Args:\n",
    "        job_name: Name of the Azure ML job\n",
    "        max_wait_minutes: Maximum time to wait (default: 30 minutes)\n",
    "        check_interval: Time between status checks in seconds (default: 30 seconds)\n",
    "    \"\"\"\n",
    "    print(f\"‚è≥ Waiting for job completion (max {max_wait_minutes} minutes)...\")\n",
    "    print(f\"üîÑ Checking every {check_interval} seconds\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    max_wait_seconds = max_wait_minutes * 60\n",
    "\n",
    "    while time.time() - start_time < max_wait_seconds:\n",
    "        try:\n",
    "            current_job = ml_client.jobs.get(job_name)\n",
    "            elapsed_minutes = (time.time() - start_time) / 60\n",
    "\n",
    "            print(f\"[{elapsed_minutes:.1f}m] Status: {current_job.status}\")\n",
    "\n",
    "            if current_job.status == \"Completed\":\n",
    "                print(\"‚úÖ Job completed successfully!\")\n",
    "                return True\n",
    "            elif current_job.status == \"Failed\":\n",
    "                print(\"‚ùå Job failed!\")\n",
    "                return False\n",
    "            elif current_job.status == \"Canceled\":\n",
    "                print(\"‚ö†Ô∏è Job was canceled!\")\n",
    "                return False\n",
    "\n",
    "            time.sleep(check_interval)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error checking job status: {str(e)}\")\n",
    "            break\n",
    "\n",
    "    print(f\"‚è∞ Timeout reached after {max_wait_minutes} minutes\")\n",
    "    print(\"üí° Job may still be running - check Azure ML Studio for updates\")\n",
    "    return False\n",
    "\n",
    "# Uncomment the following line to wait for job completion\n",
    "# wait_for_job_completion(job_name, max_wait_minutes=15)\n",
    "\n",
    "print(\"üí° To wait for job completion, uncomment and run the above function call\")\n",
    "print(f\"üåê Or monitor progress in Azure ML Studio: {current_job.studio_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2364c1c5",
   "metadata": {},
   "source": [
    "## Step 8: Retrieve Results and Manage Models\n",
    "\n",
    "Once the training job is complete, we can retrieve the trained model, view metrics, and register the model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75993523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download job outputs and artifacts\n",
    "print(f\"üì• Retrieving job outputs for: {job_name}\")\n",
    "\n",
    "try:\n",
    "    # Get the completed job\n",
    "    completed_job = ml_client.jobs.get(job_name)\n",
    "\n",
    "    if completed_job.status == \"Completed\":\n",
    "        print(\"‚úÖ Job completed successfully!\")\n",
    "\n",
    "        # Create outputs directory\n",
    "        outputs_dir = Path(\"../outputs/job_artifacts\")\n",
    "        outputs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        print(f\"üìÅ Downloading artifacts to: {outputs_dir}\")\n",
    "\n",
    "        # Download job outputs\n",
    "        try:\n",
    "            ml_client.jobs.download(\n",
    "                name=job_name,\n",
    "                download_path=outputs_dir,\n",
    "                output_name=\"default\"\n",
    "            )\n",
    "            print(\"‚úÖ Artifacts downloaded successfully!\")\n",
    "\n",
    "            # List downloaded files\n",
    "            print(\"\\\\nüìã Downloaded files:\")\n",
    "            for file_path in outputs_dir.rglob(\"*\"):\n",
    "                if file_path.is_file():\n",
    "                    relative_path = file_path.relative_to(outputs_dir)\n",
    "                    print(f\"   üìÑ {relative_path}\")\n",
    "\n",
    "        except Exception as download_error:\n",
    "            print(f\"‚ö†Ô∏è Could not download artifacts: {str(download_error)}\")\n",
    "            print(\"üí° This is normal if the job is still running or no artifacts were created\")\n",
    "\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Job status: {completed_job.status}\")\n",
    "        print(\"üí° Wait for job completion before downloading artifacts\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error retrieving job: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7885336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View training metrics from MLflow\n",
    "print(\"üìä Retrieving training metrics...\")\n",
    "\n",
    "try:\n",
    "    # List experiments\n",
    "    experiments = ml_client.experiments.list()\n",
    "\n",
    "    print(\"\\\\nüìã Available experiments:\")\n",
    "    for exp in experiments:\n",
    "        print(f\"   üß™ {exp.name}\")\n",
    "\n",
    "    # Try to get our specific experiment\n",
    "    experiment_name = job_config[\"experiment_name\"]\n",
    "\n",
    "    try:\n",
    "        experiment = ml_client.experiments.get(experiment_name)\n",
    "        print(f\"\\\\n‚úÖ Found experiment: {experiment.name}\")\n",
    "        print(f\"üìù Description: {experiment.description or 'No description'}\")\n",
    "\n",
    "        # List jobs in this experiment\n",
    "        jobs_in_experiment = ml_client.jobs.list(parent_job_name=experiment_name)\n",
    "\n",
    "        print(f\"\\\\nüîç Jobs in experiment '{experiment_name}':\")\n",
    "        for job in jobs_in_experiment:\n",
    "            print(f\"   üéØ {job.name} - Status: {job.status}\")\n",
    "\n",
    "    except Exception as exp_error:\n",
    "        print(f\"‚ö†Ô∏è Could not retrieve experiment details: {str(exp_error)}\")\n",
    "        print(\"üí° The experiment may not exist yet or may have a different name\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error retrieving experiments: {str(e)}\")\n",
    "\n",
    "print(\"\\\\nüí° For detailed metrics and visualizations:\")\n",
    "print(\"   üåê Visit Azure ML Studio: https://ml.azure.com\")\n",
    "print(f\"   üìä Navigate to Experiments ‚Üí {experiment_name}\")\n",
    "print(\"   üìà View metrics, logs, and model artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5033cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the trained model (optional)\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.entities import Model\n",
    "\n",
    "print(\"üéØ Model Registration (Optional)\")\n",
    "print(\"This step registers your trained model in Azure ML Model Registry\")\n",
    "print(\"for easy deployment and versioning.\\\\n\")\n",
    "\n",
    "def register_model_from_job(job_name, model_name=\"lstm-time-series-model\"):\n",
    "    \"\"\"Register a model from a completed training job\"\"\"\n",
    "\n",
    "    try:\n",
    "        # Get the completed job\n",
    "        completed_job = ml_client.jobs.get(job_name)\n",
    "\n",
    "        if completed_job.status != \"Completed\":\n",
    "            print(f\"‚ö†Ô∏è Job status: {completed_job.status}\")\n",
    "            print(\"üí° Model registration requires a completed job\")\n",
    "            return None\n",
    "\n",
    "        print(f\"üìù Registering model: {model_name}\")\n",
    "\n",
    "        # Create model entity\n",
    "        model = Model(\n",
    "            name=model_name,\n",
    "            description=\"LSTM model for time series forecasting trained on Azure ML\",\n",
    "            type=AssetTypes.MLFLOW_MODEL,\n",
    "            path=f\"azureml://jobs/{job_name}/outputs/artifacts/lstm_model\",\n",
    "            tags={\n",
    "                \"model_type\": \"LSTM\",\n",
    "                \"framework\": \"PyTorch\",\n",
    "                \"task\": \"time_series_forecasting\",\n",
    "                \"training_job\": job_name,\n",
    "                \"experiment\": completed_job.experiment_name\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Register the model\n",
    "        registered_model = ml_client.models.create_or_update(model)\n",
    "\n",
    "        print(\"‚úÖ Model registered successfully!\")\n",
    "        print(\"üìã Model Details:\")\n",
    "        print(f\"   Name: {registered_model.name}\")\n",
    "        print(f\"   Version: {registered_model.version}\")\n",
    "        print(f\"   ID: {registered_model.id}\")\n",
    "        print(f\"   Type: {registered_model.type}\")\n",
    "\n",
    "        return registered_model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error registering model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Uncomment to register the model\n",
    "# registered_model = register_model_from_job(job_name)\n",
    "\n",
    "print(\"üí° To register your trained model:\")\n",
    "print(\"   1. Uncomment the line above\")\n",
    "print(\"   2. Ensure your training job has completed successfully\")\n",
    "print(\"   3. Run this cell\")\n",
    "print(\"\\\\nüîó You can also register models manually in Azure ML Studio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31c6cbd",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "üéâ **Congratulations!** You've successfully completed the Azure ML training tutorial. Here's what you've accomplished:\n",
    "\n",
    "### ‚úÖ What You've Learned\n",
    "\n",
    "1. **Azure ML Setup**: Configured Azure ML workspace and authentication\n",
    "2. **Compute Resources**: Set up and validated compute clusters for training\n",
    "3. **Environment Management**: Created custom conda environments for PyTorch\n",
    "4. **Training Scripts**: Built Azure ML-optimized training code with MLflow tracking\n",
    "5. **Job Submission**: Submitted remote training jobs to Azure ML compute\n",
    "6. **Monitoring**: Tracked job progress and status in real-time\n",
    "7. **Model Management**: Retrieved artifacts and learned about model registration\n",
    "\n",
    "### üöÄ Next Steps\n",
    "\n",
    "- **Experiment with hyperparameters**: Modify the training command to test different model architectures\n",
    "- **Scale up training**: Use larger compute instances or distributed training\n",
    "- **Deploy models**: Create real-time or batch inference endpoints\n",
    "- **Set up pipelines**: Automate training workflows with Azure ML Pipelines\n",
    "- **Add data sources**: Connect to Azure storage for larger datasets\n",
    "\n",
    "### üìö Additional Resources\n",
    "\n",
    "- [Azure ML Documentation](https://docs.microsoft.com/azure/machine-learning/)\n",
    "- [MLflow Integration](https://docs.microsoft.com/azure/machine-learning/how-to-use-mlflow)\n",
    "- [PyTorch on Azure ML](https://docs.microsoft.com/azure/machine-learning/how-to-train-pytorch)\n",
    "\n",
    "### üí° Tips for Production\n",
    "\n",
    "- Use Azure ML Pipelines for reproducible workflows\n",
    "- Implement proper data versioning and lineage\n",
    "- Set up automated model validation and testing\n",
    "- Configure monitoring and alerts for model performance\n",
    "- Use Azure ML's built-in security and compliance features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_env",
   "language": "python",
   "name": "aml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
