# Azure ML v2 LSTM Time Series Forecasting Project

## âš ï¸ CAUTION: Development Environment Only

**This project is designed for development and learning purposes only with sample/synthetic data.**

For production workloads with actual data, please follow the comprehensive infrastructure, network, and security guidance provided in the official Azure Machine Learning documentation:

- **Enterprise Security**: [Azure Machine Learning Enterprise Security](https://learn.microsoft.com/en-us/azure/machine-learning/concept-enterprise-security?view=azureml-api-2)
- **Secure Workspace Setup**: [Create a Secure Azure ML Workspace](https://learn.microsoft.com/en-us/azure/machine-learning/tutorial-create-secure-workspace?view=azureml-api-2)

Production deployments require proper consideration of:
- Network isolation and private endpoints
- Identity and access management
- Data governance and compliance
- Security monitoring and auditing
- Enterprise-grade infrastructure design

## Overview

This project implements an end-to-end LSTM Time Series Forecasting solution using:
- **Azure Machine Learning v2 SDK**
- **PyTorch LSTM models (CPU-only)**
- **MLflow for experiment tracking**
- **Poetry for dependency management**
- **MLOps pipelines and automation**

## ğŸš€ Key Features

- Complete project structure with modular architecture
- CPU-only PyTorch installation (no CUDA dependencies)
- Optimized Poetry configuration for fast dependency resolution
- Azure ML workspace integration with proper permissions
- MLflow experiment tracking with v2 compatibility
- Docker environment setup
- Comprehensive testing framework
- Built-in troubleshooting for common Azure ML issues

## ğŸ“ Project Structure

```
aml-sdk-demo/
â”œâ”€â”€ README.md                      # Project documentation
â”œâ”€â”€ pyproject.toml                 # Poetry configuration (CPU-only)
â”œâ”€â”€ poetry.lock                    # Clean lockfile
â”œâ”€â”€ environment.yml                # Conda environment
â”œâ”€â”€ requirements.in                # Input requirements
â”œâ”€â”€ .env.example                   # Environment variables template
â”œâ”€â”€ setup.sh                       # Environment setup script
â”œâ”€â”€ fast_setup.sh                  # Quick setup script
â”œâ”€â”€ LICENSE                        # Project license
â”‚
â”œâ”€â”€ src/                           # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ azure_ml_training/         # Azure ML training scripts
â”‚   â”‚   â”œâ”€â”€ train_lstm.py          # Main training script (MLflow v2 compatible)
â”‚   â”‚   â”œâ”€â”€ submit_training_job.py # Job submission script
â”‚   â”‚   â”œâ”€â”€ environment.yml        # Conda environment for Azure ML
â”‚   â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”‚   â””â”€â”€ README.md              # Training documentation
â”‚   â”œâ”€â”€ training/                  # Production training framework
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ train_lstm.py          # Advanced modular training script
â”‚   â”œâ”€â”€ data_processing/           # Data preprocessing modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ preprocessor.py        # Time series preprocessing
â”‚   â”œâ”€â”€ models/                    # Model definitions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ lstm_model.py          # PyTorch LSTM implementation
â”‚   â”‚   â””â”€â”€ lstm_model_seq2seq.py  # Sequence-to-sequence variant
â”‚   â”œâ”€â”€ utils/                     # Utility functions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ azure_ml_config.py     # Azure ML configuration utilities
â”‚   â”‚   â””â”€â”€ azure_ml_utils.py      # Azure ML helper functions
â”‚   â””â”€â”€ inference/                 # Inference scripts
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ score.py               # Model scoring script
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_setup_workspace.ipynb   # Azure ML workspace setup & troubleshooting
â”‚   â”œâ”€â”€ 02_data_exploration.ipynb  # EDA and preprocessing
â”‚   â”œâ”€â”€ 03_model_training.ipynb    # Interactive training
â”‚   â”œâ”€â”€ 04_azure_ml_training_tutorial.ipynb # Azure ML training tutorial
â”‚
â”œâ”€â”€ mlops/                         # MLOps configuration
â”‚   â”œâ”€â”€ pipelines/                 # Azure ML pipelines
â”‚   â”‚   â””â”€â”€ training_pipeline.py   # Automated training pipeline
â”‚   â”œâ”€â”€ environments/              # ML environments
â”‚   â”‚   â”œâ”€â”€ Dockerfile             # Custom environment
â”‚   â”‚   â”œâ”€â”€ ml_environment.yml     # Environment specification
â”‚   â”‚   â””â”€â”€ requirements.txt       # Environment dependencies
â”‚   â””â”€â”€ compute/                   # Compute configurations
â”‚       â””â”€â”€ setup_compute.py       # Compute cluster setup
â”‚
â”œâ”€â”€ configs/                       # Configuration files
â”‚   â”œâ”€â”€ model_config.yaml          # Model hyperparameters
â”‚   â””â”€â”€ pipeline_config.yaml       # Pipeline configuration
â”‚
â”œâ”€â”€ docker/                        # Docker configuration
â”‚   â”œâ”€â”€ Dockerfile                 # ML environment
â”‚   â””â”€â”€ requirements.txt           # Docker dependencies
â”‚
â”œâ”€â”€ scripts/                       # Setup and utility scripts
â”‚   â””â”€â”€ fast_setup.sh              # Quick environment setup
â”‚
â”œâ”€â”€ data/                          # Data directory
â”‚
â”œâ”€â”€ outputs/                       # Model outputs and logs
â”‚
â””â”€â”€ tests/                         # Unit tests
    â”œâ”€â”€ test_model.py              # Model unit tests
    â””â”€â”€ test_preprocessor.py       # Preprocessing tests
```

## ğŸ”§ Prerequisites and Setup

### Azure Prerequisites

#### Azure Resources Required
- **Azure Subscription** with active billing
- **Resource Group** containing the ML workspace
- **Azure Machine Learning Workspace** (created manually or via Azure Portal)
- **Storage Account** (automatically created with ML workspace)
- **Key Vault** (automatically created with ML workspace)
- **Application Insights** (automatically created with ML workspace)

#### Azure Roles and Permissions Required

Your Azure account **MUST** have the following roles assigned:

##### At Subscription Level:
- **Contributor** or **Owner** (for resource management)
- **Azure AI User** (built-in RBAC role designed for individuals who need to use AI resources)
- **User Access Administrator** (for role assignments)

##### At Resource Group Level:
- **Contributor** (minimum required)
- **Azure AI User** (inherited from Subscription)
- **AzureML Data Scientist** (recommended for AzureML workspace)
- **AzureML Compute Operator** (recommended for AzureML workspace)
- **Storage Blob Data Contributor** (recommended for Storage Account)

##### Critical: Storage Account Permissions
The Azure ML workspace's **managed identity** needs:
- **Storage Blob Data Contributor** role on the default storage account
- **Storage File Data Privileged Contributor** role on the default storage account

### Local Development Prerequisites

#### Required Software
```bash
# Python 3.11+ required
python --version  # Should show 3.11.x or higher

# Azure CLI (latest version)
az --version

# Poetry for dependency management
poetry --version
```

#### Environment Variables
Create a `.env` file in the project root by copying `.env.example` and renaming it to `.env`:
```bash
# Azure ML Configuration
AZURE_SUBSCRIPTION_ID="your-subscription-id"
AZURE_RESOURCE_GROUP="your-resource-group"
AZURE_ML_WORKSPACE_NAME="your-workspace-name"
AZURE_TENANT_ID="your-tenant-id"

# Optional: Specific regions
AZURE_LOCATION="eastus2"  # or your preferred region
```

## ğŸ› ï¸ Installation and Setup

### Step 1: Clone and Install Dependencies

```bash
# Clone the repository
git clone <repository-url>
cd aml-sdk-demo

# Create a directory to point the virtual environment created by Poetry in your project directory
mkdir .venv

# Install dependencies (fast, no CUDA downloads)
poetry install --no-root

# Activate virtual environment
poetry shell

# Add environment to Jupyter kernelspec to use in Notebook
python -m ipykernel install --user --name .venv

```

### Step 2: Configure Azure Authentication

```bash
# Login to Azure
az login

# Set your subscription
az account set --subscription "your-subscription-id"

# Verify Azure ML workspace access
az ml workspace show \
    --name "your-workspace-name" \
    --resource-group "your-resource-group"
```

### Step 3: Set Storage Permissions (Critical - If not already done during Resource Creation)

```bash
# Get workspace managed identity principal ID
WORKSPACE_PRINCIPAL_ID=$(az ml workspace show \
    --name "your-workspace-name" \
    --resource-group "your-resource-group" \
    --query "identity.principal_id" \
    --output tsv)

# Get storage account resource ID
STORAGE_ACCOUNT_ID=$(az storage account list \
    --resource-group "your-resource-group" \
    --query "[?contains(name, 'your-storage-account-name')].id" \
    --output tsv)

# Assign Storage Blob Data Contributor role (CRITICAL FOR JOB SUBMISSION)
az role assignment create \
    --assignee $WORKSPACE_PRINCIPAL_ID \
    --role "Storage Blob Data Contributor" \
    --scope $STORAGE_ACCOUNT_ID

# Verify the role assignment
az role assignment list \
    --assignee $WORKSPACE_PRINCIPAL_ID \
    --scope $STORAGE_ACCOUNT_ID \
    --output table
```

### Step 4: Run Setup Notebook

Open the Jupyter Notebook: notebooks/01_setup_workspace.ipynb

In Jupyter Notebook, select Kernel to be the poetry virtual environment that should have been created following Step 1.

The notebook will:
- âœ… Test Azure connectivity
- âœ… Verify workspace access
- âœ… Create/validate compute clusters
- âœ… Setup ML environments
- âœ… Test job submission
- âœ… Provide troubleshooting guidance

## ğŸ“– Usage Guide

### Training Script Options

#### 1. Simple Azure ML Training (`src/azure_ml_training/train_lstm.py`)
- **Purpose**: Quick Azure ML job submission with robust error handling
- **Use Case**: Simple experiments, testing Azure ML functionality, production Azure ML jobs
- **Features**: Self-contained script, MLflow v2 compatibility, synthetic data generation
- **Pros**: Fast setup, minimal dependencies, robust error handling
- **Cons**: Limited to synthetic data, basic preprocessing

#### 2. Production Training Framework (`src/training/train_lstm.py`)
- **Purpose**: Modular, scalable training architecture
- **Use Case**: Production workloads, complex preprocessing, real datasets (Remember to prepare your Subscription and resources for Production, see CAUTION above)
- **Features**: Class-based trainer, external preprocessor, configurable models
- **Pros**: Highly modular, scalable, production-ready, real data support
- **Cons**: More complex setup, requires external modules

#### 3. Interactive Training (Notebooks)
- Use `notebooks/03_model_training.ipynb` for experimentation
- MLflow automatically tracks experiments
- Real-time monitoring in Azure ML Studio

### Daily Development Workflow

```bash
# Start development session
poetry shell

# For Azure ML training jobs
python src/azure_ml_training/train_lstm.py

# For local training experiments
python src/training/train_lstm.py

# For pipeline execution
python mlops/pipelines/training_pipeline.py
```

## ğŸš¨ Common Issues and Solutions

### Issue: "AuthorizationFailure" during Job Submission
**Cause**: Azure ML workspace managed identity lacks storage permissions  
**Solution**: Run the storage permission commands in Step 3 above

### Issue: Compute Cluster Creation Fails
**Cause**: Insufficient permissions or quota limits  
**Solution**: Ensure Contributor role on resource group and check VM quotas

### Issue: Environment Build Failures
**Cause**: Package conflicts or missing dependencies  
**Solution**: Use curated environments or simplify custom environment dependencies

### Issue: Network Connectivity Problems
**Cause**: Firewall rules or DNS issues  
**Solution**: Ensure Azure services are allowed and test connectivity

## ğŸš€ Next Steps

### Development Enhancements
1. **Real Data Integration**: Replace synthetic data with actual time series datasets
2. **Model Improvements**: Experiment with different architectures and hyperparameters
3. **Feature Engineering**: Add advanced preprocessing and feature extraction

### Production Scaling
1. **GPU Support**: Add GPU compute targets for larger models
2. **Model Deployment**: Set up real-time inference endpoints
3. **Pipeline Automation**: Deploy automated retraining pipelines
4. **Monitoring**: Implement model monitoring and drift detection

### MLOps Integration
1. **CI/CD Integration**: Connect with Azure DevOps or GitHub Actions
2. **Model Registry**: Implement model versioning and approval workflows
3. **A/B Testing**: Set up model comparison and gradual rollout

## ğŸ’¡ Best Practices

### Azure ML Integration
- **Storage Permissions**: Always configure managed identity permissions first
- **Compute Management**: Use system-assigned managed identity for clusters
- **Environment Strategy**: Start with curated environments, customize as needed
- **Error Handling**: Implement comprehensive error detection and recovery

### Poetry + PyTorch Best Practices
- **CPU-First Development**: Use CPU versions for development, GPU for production
- **Clean Dependencies**: Remove unused CUDA packages to avoid bloat
- **Performance Tuning**: Use Poetry optimization settings for faster resolution

### MLflow Integration
- **Centralized Tracking**: Use Azure ML's built-in MLflow tracking
- **Experiment Organization**: Structure experiments with meaningful names and tags
- **Model Registry**: Use MLflow model registry for version control

## ğŸ“– Documentation

- [Azure ML v2 SDK Documentation](https://docs.microsoft.com/en-us/azure/machine-learning/)
- [PyTorch Time Series Tutorial](https://pytorch.org/tutorials/beginner/transformer_tutorial.html)
- [MLflow Tracking Guide](https://mlflow.org/docs/latest/tracking.html)
- [Poetry Dependency Management](https://python-poetry.org/docs/)

## ğŸ“ Getting Help

If you encounter issues not covered here:

1. **Check Azure ML Studio**: Look for detailed error messages in the Azure ML portal
2. **Review Activity Logs**: Check Azure Activity Log for resource-level errors
3. **Enable Diagnostics**: Turn on diagnostic logging for Azure ML workspace
4. **Contact Support**: For persistent issues, contact Azure support with:
   - Subscription ID
   - Resource group name
   - Workspace name
   - Correlation ID from error messages
   - Timestamp of the issue

---
